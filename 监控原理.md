# Twitter 列表监控原理说明

## 工作原理

### 1. 浏览器自动化
- 使用 **Playwright** 控制 Chromium 浏览器
- 添加 `--disable-blink-features=AutomationControlled` 参数绕过 Twitter 的反爬虫检测
- 浏览器数据保存在 `./twitter-profile` 目录，保持登录状态

### 2. 内容提取流程

```javascript
// 1. 导航到 Twitter 列表页面
await page.goto('https://x.com/i/lists/xxxxx')

// 2. 等待页面元素加载
await page.waitForSelector('[data-testid="primaryColumn"]')

// 3. 滚动页面加载更多推文
await page.evaluate(() => window.scrollBy(0, 1000))

// 4. 提取推文数据
const tweets = await page.evaluate(() => {
  // 在浏览器环境中执行
  const elements = document.querySelectorAll('[data-testid="tweet"]')
  // 提取每条推文的：
  // - 文本内容: [data-testid="tweetText"]
  // - 用户信息: [data-testid="User-Name"]
  // - 发布时间: time 元素
  // - 推文链接: a[href*="/status/"]
})
```

### 3. 数据处理
- **去重机制**：使用推文 URL 中的 ID 作为唯一标识
- **24小时过滤**：只显示过去24小时内的推文
- **实时推送**：通过 WebSocket 将新推文推送到前端

### 4. 监控循环
```
每30秒 → 刷新页面 → 提取推文 → 对比新旧 → 推送更新
```

## 项目结构

```
playwright-twitter/
├── server.js           # 后端服务器（核心逻辑）
├── public/
│   └── index.html      # 前端界面
├── screenshots/        # 调试截图目录
├── twitter-profile/    # 浏览器数据目录
├── tweets-data.json    # 推文数据存储
├── package.json        # 项目配置
├── start-monitor.sh    # 启动脚本
└── README.md          # 项目文档
```

## 关键技术点

1. **绕过反爬虫**
   - 使用真实浏览器环境
   - 禁用自动化特征
   - 保持登录状态

2. **实时监控**
   - 定时刷新机制
   - WebSocket 实时通信
   - 数据持久化存储

3. **数据提取**
   - DOM 选择器定位元素
   - 浏览器环境执行 JavaScript
   - 结构化数据提取